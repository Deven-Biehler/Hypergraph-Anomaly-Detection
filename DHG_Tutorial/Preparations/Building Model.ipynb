{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Spectral-based Model\n",
    "In the following examples, we will build two typical spectral-based models (GCN and HGNN ) on graph and hypergraph, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GCNConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        self.theta = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, g: dhg.Graph) -> torch.Tensor:\n",
    "        X = self.theta(X)\n",
    "        X_ = g.smoothing_with_GCN(X)\n",
    "        X_ = self.drop(self.act(X_))\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HGNNConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        self.theta = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, hg: dhg.Hypergraph) -> torch.Tensor:\n",
    "        X = self.theta(X)\n",
    "        X_ = hg.smoothing_with_HGNN(X)\n",
    "        X_ = self.drop(self.act(X_))\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Spatial-based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building GraphSAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\biehl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GraphSAGEConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        aggr: str = \"mean\",\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert aggr in [\"mean\"], \"Currently, only mean aggregation is supported.\"\n",
    "        self.aggr = aggr\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        if aggr == \"mean\":\n",
    "            self.theta = nn.Linear(in_channels * 2, out_channels, bias=bias)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def forward(self, X: torch.Tensor, g: dhg.Graph) -> torch.Tensor:\n",
    "        if self.aggr == \"mean\":\n",
    "            X_nbr = g.v2v(X, aggr=\"mean\")\n",
    "            X = torch.cat([X, X_nbr], dim=1)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        X_ = self.theta(X)\n",
    "        X_ = self.drop(self.act(X_))\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building HGNN+ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HGNNPConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        self.theta = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, hg: dhg.Hypergraph) -> torch.Tensor:\n",
    "        X = self.theta(X)\n",
    "        Y = hg.v2e(X, aggr=\"mean\")\n",
    "        X_ = hg.e2v(Y, aggr=\"mean\")\n",
    "        X_ = self.drop(self.act(X_))\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building GAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GATConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "        atten_neg_slope: float = 0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.atten_dropout = nn.Dropout(drop_rate)\n",
    "        self.atten_act = nn.LeakyReLU(atten_neg_slope)\n",
    "        self.act = nn.ELU(inplace=True)\n",
    "        self.theta = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "        self.atten_src = nn.Linear(out_channels, 1, bias=False)\n",
    "        self.atten_dst = nn.Linear(out_channels, 1, bias=False)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, g: dhg.Graph) -> torch.Tensor:\n",
    "        X = self.theta(X)\n",
    "        x_for_src = self.atten_src(X)\n",
    "        x_for_dst = self.atten_dst(X)\n",
    "        e_atten_score = x_for_src[g.e_src] + x_for_dst[g.e_dst]\n",
    "        e_atten_score = self.atten_dropout(self.atten_act(e_atten_score).squeeze())\n",
    "        X_ = g.v2v(X, aggr=\"softmax_then_sum\", e_weight=e_atten_score)\n",
    "        X_ = self.act(X_)\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building hypergraph convolution with different hyperedge weights model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HGATConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "        atten_neg_slope: float = 0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.atten_dropout = nn.Dropout(drop_rate)\n",
    "        self.atten_act = nn.LeakyReLU(atten_neg_slope)\n",
    "        self.act = nn.ELU(inplace=True)\n",
    "        self.theta_vertex = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "        self.theta_hyperedge = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "        self.atten_vertex = nn.Linear(out_channels, 1, bias=False)\n",
    "        self.atten_hyperedge = nn.Linear(out_channels, 1, bias=False)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, Y: torch.Tensor, hg: dhg.Hypergraph) -> torch.Tensor:\n",
    "        X = self.theta_vertex(X)\n",
    "        Y = self.theta_hyperedge(Y)\n",
    "        x_for_vertex = self.atten_vertex(X)\n",
    "        y_for_hyperedge = self.atten_hyperedge(Y)\n",
    "        v2e_atten_score = x_for_vertex[hg.v2e_src] + y_for_hyperedge[hg.v2e_dst]\n",
    "        e2v_atten_score = y_for_hyperedge[hg.e2v_src] + x_for_vertex[hg.e2v_dst]\n",
    "        v2e_atten_score = self.atten_dropout(self.atten_act(v2e_atten_score).squeeze())\n",
    "        e2v_atten_score = self.atten_dropout(self.atten_act(e2v_atten_score).squeeze())\n",
    "        Y_ = hg.v2e(X, aggr=\"softmax_then_sum\", v2e_weight=v2e_atten_score)\n",
    "        X_ = hg.e2v(Y_, aggr=\"softmax_then_sum\", e2v_weight=e2v_atten_score)\n",
    "        X_ = self.act(X_)\n",
    "        Y_ = self.act(Y_)\n",
    "        return X_, Y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Hybrid Operation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HOMConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        self.theta = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, g: dhg.Graph) -> torch.Tensor:\n",
    "        X = self.theta(X)\n",
    "        X_spectral = g.smoothing_with_GCN(X)\n",
    "        X_spatial = g.v2v(X, aggr=\"mean\")\n",
    "        X_ = (X_spectral + X_spatial) / 2\n",
    "        X_ = self.drop(self.act(X_))\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Hybrid Structure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HSMConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias: bool = True,\n",
    "        drop_rate: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "        self.theta = nn.Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "    def forward(self, X: torch.Tensor, g: dhg.Graph, hg: dhg.Hypergraph) -> torch.Tensor:\n",
    "        X = self.theta(X)\n",
    "        X_g = g.v2v(X, aggr=\"mean\")\n",
    "        X_hg = hg.v2v(X, aggr=\"mean\")\n",
    "        X_ = (X_g + X_hg) / 2\n",
    "        X_ = self.drop(self.act(X_))\n",
    "        return X_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
